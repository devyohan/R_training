{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'readr' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'purrr' was built under R version 3.4.2\"Warning message:\n",
      "\"package 'dplyr' was built under R version 3.4.2\"\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(readr)\n",
    "library(stringr)\n",
    "library(purrr)\n",
    "library(tibble)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenize_words <- function(x){\n",
    "  x <- x %>% \n",
    "    str_replace_all('([[:punct:]]+)', ' \\\\1') %>% \n",
    "    str_split(' ') %>%\n",
    "    unlist()\n",
    "  x[x != \"\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_stories <- function(lines, only_supporting = FALSE){\n",
    "  lines <- lines %>% \n",
    "    str_split(\" \", n = 2) %>%\n",
    "    map_df(~tibble(nid = as.integer(.x[[1]]), line = .x[[2]]))\n",
    "  \n",
    "  lines <- lines %>%\n",
    "    mutate(\n",
    "      split = map(line, ~str_split(.x, \"\\t\")[[1]]),\n",
    "      q = map_chr(split, ~.x[1]),\n",
    "      a = map_chr(split, ~.x[2]),\n",
    "      supporting = map(split, ~.x[3] %>% str_split(\" \") %>% unlist() %>% as.integer()),\n",
    "      story_id = c(0, cumsum(nid[-nrow(.)] > nid[-1]))\n",
    "    ) %>%\n",
    "    select(-split)\n",
    "  \n",
    "  stories <- lines %>%\n",
    "    filter(is.na(a)) %>%\n",
    "    select(nid_story = nid, story_id, story = q)\n",
    "  \n",
    "  questions <- lines %>%\n",
    "    filter(!is.na(a)) %>%\n",
    "    select(-line) %>%\n",
    "    left_join(stories, by = \"story_id\") %>%\n",
    "    filter(nid_story < nid)\n",
    "  \n",
    "  if(only_supporting){\n",
    "    questions <- questions %>%\n",
    "      filter(map2_lgl(nid_story, supporting, ~.x %in% .y))\n",
    "  }\n",
    "  \n",
    "  questions %>%\n",
    "    group_by(story_id, nid, question = q, answer = a) %>%\n",
    "    summarise(story = paste(story, collapse = \" \")) %>%\n",
    "    ungroup() %>% \n",
    "    mutate(\n",
    "      question = map(question, ~tokenize_words(.x)),\n",
    "      story = map(story, ~tokenize_words(.x)),\n",
    "      id = row_number()\n",
    "    ) %>%\n",
    "    select(id, question, answer, story)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorize_stories <- function(data, vocab, story_maxlen, query_maxlen){\n",
    "  \n",
    "  questions <- map(data$question, function(x){\n",
    "    map_int(x, ~which(.x == vocab))\n",
    "  })\n",
    "  \n",
    "  stories <- map(data$story, function(x){\n",
    "    map_int(x, ~which(.x == vocab))\n",
    "  })\n",
    "  \n",
    "  # \"\" represents padding\n",
    "  answers <- sapply(c(\"\", vocab), function(x){\n",
    "    as.integer(x == data$answer)\n",
    "  })\n",
    "  \n",
    "  list(\n",
    "    questions = pad_sequences(questions, maxlen = query_maxlen),\n",
    "    stories   = pad_sequences(stories, maxlen = story_maxlen),\n",
    "    answers   = answers\n",
    "  )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenges <- list(\n",
    "  # QA1 with 10,000 samples\n",
    "  single_supporting_fact_10k = \"%stasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_%s.txt\",\n",
    "  # QA2 with 10,000 samples\n",
    "  two_supporting_facts_10k = \"%stasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_%s.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenge_type <- \"single_supporting_fact_10k\"\n",
    "challenge <- challenges[[challenge_type]]\n",
    "max_length <- 999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "path <- get_file(\n",
    "  fname = \"babi-tasks-v1-2.tar.gz\",\n",
    "  origin = \"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\"\n",
    ")\n",
    "untar(path, exdir = str_replace(path, fixed(\".tar.gz\"), \"/\"))\n",
    "path <- str_replace(path, fixed(\".tar.gz\"), \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'bindrcpp' was built under R version 3.4.2\""
     ]
    }
   ],
   "source": [
    "# Reading training and test data\n",
    "train <- read_lines(sprintf(challenge, path, \"train\")) %>%\n",
    "  parse_stories() %>%\n",
    "  filter(map_int(story, ~length(.x)) <= max_length)\n",
    "\n",
    "test <- read_lines(sprintf(challenge, path, \"test\")) %>%\n",
    "  parse_stories() %>%\n",
    "  filter(map_int(story, ~length(.x)) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the vocabulary\n",
    "all_data <- bind_rows(train, test)\n",
    "vocab <- c(unlist(all_data$question), all_data$answer, \n",
    "           unlist(all_data$story)) %>%\n",
    "  unique() %>%\n",
    "  sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size <- length(vocab) + 1\n",
    "story_maxlen <- map_int(all_data$story, ~length(.x)) %>% max()\n",
    "query_maxlen <- map_int(all_data$question, ~length(.x)) %>% max()\n",
    "\n",
    "# Vectorized versions of training and test sets\n",
    "train_vec <- vectorize_stories(train, vocab, story_maxlen, query_maxlen)\n",
    "test_vec <- vectorize_stories(test, vocab, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "sequence <- layer_input(shape = c(story_maxlen))\n",
    "question <- layer_input(shape = c(query_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoders\n",
    "# Embed the input sequence into a sequence of vectors\n",
    "sequence_encoder_m <- keras_model_sequential()\n",
    "sequence_encoder_m %>%\n",
    "  layer_embedding(input_dim = vocab_size, output_dim = 64) %>%\n",
    "  layer_dropout(rate = 0.3)\n",
    "# output: (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embed the input into a sequence of vectors of size query_maxlen\n",
    "sequence_encoder_c <- keras_model_sequential()\n",
    "sequence_encoder_c %>%\n",
    "  layer_embedding(input_dim = vocab_size, output = query_maxlen) %>%\n",
    "  layer_dropout(rate = 0.3)\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embed the question into a sequence of vectors\n",
    "question_encoder <- keras_model_sequential()\n",
    "question_encoder %>%\n",
    "  layer_embedding(input_dim = vocab_size, output_dim = 64, \n",
    "                  input_length = query_maxlen) %>%\n",
    "  layer_dropout(rate = 0.3)\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "sequence_encoded_m <- sequence_encoder_m(sequence)\n",
    "sequence_encoded_c <- sequence_encoder_c(sequence)\n",
    "question_encoded <- question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match <- list(sequence_encoded_m, question_encoded) %>%\n",
    "  layer_dot(axes = c(2,2)) %>%\n",
    "  layer_activation(\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the match matrix with the second input vector sequence\n",
    "response <- list(match, sequence_encoded_c) %>%\n",
    "  layer_add() %>%\n",
    "  layer_permute(c(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the match matrix with the question vector sequence\n",
    "answer <- list(response, question_encoded) %>%\n",
    "  layer_concatenate() %>%\n",
    "  # The original paper uses a matrix multiplication for this reduction step.\n",
    "  # We choose to use an RNN instead.\n",
    "  layer_lstm(32) %>%\n",
    "  # One regularization layer -- more would probably be needed.\n",
    "  layer_dropout(rate = 0.3) %>%\n",
    "  layer_dense(vocab_size) %>%\n",
    "  # We output a probability distribution over the vocabulary\n",
    "  layer_activation(\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the final model\n",
    "model <- keras_model(inputs = list(sequence, question), answer)\n",
    "model %>% compile(\n",
    "  optimizer = \"rmsprop\",\n",
    "  loss = \"categorical_crossentropy\",\n",
    "  metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model %>% fit(\n",
    "  x = list(train_vec$stories, train_vec$questions),\n",
    "  y = train_vec$answers,\n",
    "  batch_size = 32,\n",
    "  epochs = 120,\n",
    "  validation_data = list(list(test_vec$stories, test_vec$questions), test_vec$answers)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "________________________________________________________________________________\n",
       "Layer (type)              Output Shape      Param #  Connected to               \n",
       "================================================================================\n",
       "input_1 (InputLayer)      (None, 68)        0                                   \n",
       "________________________________________________________________________________\n",
       "input_2 (InputLayer)      (None, 4)         0                                   \n",
       "________________________________________________________________________________\n",
       "sequential_2 (Sequential) multiple          1408     input_1[0][0]              \n",
       "________________________________________________________________________________\n",
       "sequential_4 (Sequential) (None, 4, 64)     1408     input_2[0][0]              \n",
       "________________________________________________________________________________\n",
       "dot_1 (Dot)               (None, 68, 4)     0        sequential_2[1][0]         \n",
       "                                                     sequential_4[1][0]         \n",
       "________________________________________________________________________________\n",
       "activation_1 (Activation) (None, 68, 4)     0        dot_1[0][0]                \n",
       "________________________________________________________________________________\n",
       "sequential_3 (Sequential) multiple          88       input_1[0][0]              \n",
       "________________________________________________________________________________\n",
       "add_1 (Add)               (None, 68, 4)     0        activation_1[0][0]         \n",
       "                                                     sequential_3[1][0]         \n",
       "________________________________________________________________________________\n",
       "permute_1 (Permute)       (None, 4, 68)     0        add_1[0][0]                \n",
       "________________________________________________________________________________\n",
       "concatenate_1 (Concatenat (None, 4, 132)    0        permute_1[0][0]            \n",
       "                                                     sequential_4[1][0]         \n",
       "________________________________________________________________________________\n",
       "lstm_1 (LSTM)             (None, 32)        21120    concatenate_1[0][0]        \n",
       "________________________________________________________________________________\n",
       "dropout_6 (Dropout)       (None, 32)        0        lstm_1[0][0]               \n",
       "________________________________________________________________________________\n",
       "dense_4 (Dense)           (None, 22)        726      dropout_6[0][0]            \n",
       "________________________________________________________________________________\n",
       "activation_2 (Activation) (None, 22)        0        dense_4[0][0]              \n",
       "================================================================================\n",
       "Total params: 24,750\n",
       "Trainable params: 24,750\n",
       "Non-trainable params: 0\n",
       "________________________________________________________________________________\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)              Output Shape      Param #  Connected to               \n",
      "================================================================================\n",
      "input_1 (InputLayer)      (None, 68)        0                                   \n",
      "________________________________________________________________________________\n",
      "input_2 (InputLayer)      (None, 4)         0                                   \n",
      "________________________________________________________________________________\n",
      "sequential_2 (Sequential) multiple          1408     input_1[0][0]              \n",
      "________________________________________________________________________________\n",
      "sequential_4 (Sequential) (None, 4, 64)     1408     input_2[0][0]              \n",
      "________________________________________________________________________________\n",
      "dot_1 (Dot)               (None, 68, 4)     0        sequential_2[1][0]         \n",
      "                                                     sequential_4[1][0]         \n",
      "________________________________________________________________________________\n",
      "activation_1 (Activation) (None, 68, 4)     0        dot_1[0][0]                \n",
      "________________________________________________________________________________\n",
      "sequential_3 (Sequential) multiple          88       input_1[0][0]              \n",
      "________________________________________________________________________________\n",
      "add_1 (Add)               (None, 68, 4)     0        activation_1[0][0]         \n",
      "                                                     sequential_3[1][0]         \n",
      "________________________________________________________________________________\n",
      "permute_1 (Permute)       (None, 4, 68)     0        add_1[0][0]                \n",
      "________________________________________________________________________________\n",
      "concatenate_1 (Concatenat (None, 4, 132)    0        permute_1[0][0]            \n",
      "                                                     sequential_4[1][0]         \n",
      "________________________________________________________________________________\n",
      "lstm_1 (LSTM)             (None, 32)        21120    concatenate_1[0][0]        \n",
      "________________________________________________________________________________\n",
      "dropout_6 (Dropout)       (None, 32)        0        lstm_1[0][0]               \n",
      "________________________________________________________________________________\n",
      "dense_4 (Dense)           (None, 22)        726      dropout_6[0][0]            \n",
      "________________________________________________________________________________\n",
      "activation_2 (Activation) (None, 22)        0        dense_4[0][0]              \n",
      "================================================================================\n",
      "Total params: 24,750\n",
      "Trainable params: 24,750\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
